import logging
import pkg_resources
import logging
from tokenizers import Tokenizer
from typing import List, Union, Tuple, Dict

TOKENS_PER_IMAGE = 1601


class ClaudeContextManagement:
    """
    Manages the context for Claude LLM, including token counting, padding, and message handling.
    """

    def __init__(self):
        """
        Initializes the ClaudeContextManagement class by loading the tokenizer.
        """
        tokenizer_path = pkg_resources.resource_filename(
            __name__, 'tokenizer_claude.json')
        self.tokenizer = Tokenizer.from_file(tokenizer_path)

    def __count_tokens__(self, content: str):
        """
        Counts the number of tokens in a given content string.

        Args:
            content (str): The content to count tokens for.

        Returns:
            int: The number of tokens in the content.
        """
        tokens = self.tokenizer.encode(content).ids
        return len(tokens)

    def __pad_tokens__(self, content: str, max_tokens: int):
        """
        Pads the tokens in the content to the specified max token length.

        Args:
            content (str): The content to pad.
            max_tokens (int): The maximum number of tokens.

        Returns:
            str: The padded content.
        """
        tokens = self.tokenizer.encode(content).ids
        tokens_to_keep = tokens[:max_tokens]
        return self.tokenizer.decode(tokens_to_keep)

    def __return_chunks__(self,
                          content: str,
                          max_tokens: int,
                          overlap: int = 200):
        """
        Splits the content into chunks of a specified max token length with overlap.

        Args:
            content (str): The content to split into chunks.
            max_tokens (int): The maximum number of tokens per chunk.
            overlap (int, optional): The token overlap between chunks. Default is 200.

        Returns:
            List[str]: A list of content chunks.
        """
        content_tokens = self.tokenizer.encode(content)
        chunks = []
        for ix in range(0, len(content_tokens), max_tokens):
            if ix > 0:
                chunks.append(
                    self.tokenizer.decode(content_tokens[ix - overlap:ix +
                                                         max_tokens]))
            else:
                chunks.append(
                    self.tokenizer.decode(content_tokens[ix:ix + max_tokens]))
        return chunks

    def __call__(self,
                 messages: List[Dict],
                 max_content_length: int,
                 system_message_tokens: int = 0):
        """
        Manages and processes incoming messages, ensuring they stay within the max content length.

        Args:
            messages (List[Dict]): The list of messages to process.
            max_content_length (int): The maximum number of tokens allowed in the content.

        Returns:
            List[Dict]: The managed and processed list of messages.
        """
        system_message = None
        image_content_token_count = 0
        total_image_tokens = 0
        if messages[0].get("role") == "system":
            system_message = messages[0]
            messages = messages[1:]
        messages = messages[::-1]
        previous_role = None
        current_token_num = 0
        managed_message = []
        for ix, message in enumerate(messages):
            content = message.get("content")
            # print("CONTENT: ", content)
            role = message.get("role")
            if isinstance(content, str):
                num_tokens = self.__count_tokens__(content)
                if current_token_num + num_tokens >= max_content_length:
                    num_tokens_to_keep = max_content_length - current_token_num - 1
                    if num_tokens_to_keep <= 0:
                        break
                    content = self.__pad_tokens__(content, num_tokens_to_keep)
            elif isinstance(content, list):
                content_op = []
                for cont in content[::-1]:
                    if cont.get("type") == "image_url":
                        media_type = cont.get("image_url").get("url").split(
                            ";")[0].replace("data:", "").strip()
                        logging.info(f"MEDIA TYPE: {media_type}")
                        bs = cont.get("image_url").get("url").split(
                            f'{media_type};base64,')[-1]
                        cont = {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": media_type,
                                "data": bs
                            }
                        }
                    logging.info(f"TOKEN NUM: {current_token_num}")
                    if cont.get("type") == "image":

                        if current_token_num + image_content_token_count + TOKENS_PER_IMAGE >= max_content_length:

                            break
                        else:
                            # claude_content = []
                            content_op.append(cont)
                            image_content_token_count += TOKENS_PER_IMAGE
                            total_image_tokens += TOKENS_PER_IMAGE
                    elif cont.get("type") == "text":
                        num_tokens = self.__count_tokens__(cont.get('text'))
                        if image_content_token_count + num_tokens >= max_content_length:
                            num_tokens_to_keep = max_content_length - current_token_num - image_content_token_count - 1
                            if num_tokens_to_keep <= 0:
                                break
                            txt = self.__pad_tokens__(cont.get("text"),
                                                      num_tokens_to_keep)
                            cont["text"] = txt
                            image_content_token_count += num_tokens_to_keep
                            total_image_tokens += num_tokens_to_keep
                        else:
                            image_content_token_count += num_tokens
                            total_image_tokens += num_tokens
                        content_op.append(cont)
                content = content_op[::-1]
                # print("CONTENT: ", content)
            if ix > 0:
                if previous_role == role:
                    if isinstance(content, str):
                        managed_message[-1]["content"] += f"\n{content}"
                    elif isinstance(content, List):
                        managed_message[-1]["content"] += content
                else:
                    managed_message.append({"content": content, "role": role})
            else:
                managed_message.append({"content": content, "role": role})
            if isinstance(content, str):
                # print("CONTENT STR: ", content)
                current_token_num += self.__count_tokens__(content)
            elif isinstance(content, list):
                # print("CONTENT LIST: ", content)
                current_token_num += image_content_token_count
                image_content_token_count = 0
            previous_role = role
            # logging.info(f"TOKENS: {current_token_num}")
        managed_message = managed_message[::-1]
        if system_message:
            managed_message = [system_message] + managed_message

        logging.debug(f"SYSTEM MESSAGE TOKENS: {system_message_tokens}")
        logging.debug(f"IMAGE TOKENS: {total_image_tokens}")
        logging.debug(
            f"TOTAL TOKENS: {current_token_num + system_message_tokens}")
        print(f"SYSTEM MESSAGE TOKENS: {system_message_tokens}")
        print(f"IMAGE TOKENS: {total_image_tokens}")
        print(f"TOTAL TOKENS: {current_token_num + system_message_tokens}")
        return managed_message


# if __name__ == "__main__":
#     ctx = ClaudeContextManager()
#     # messages = [{"role": "user", "content": "Hello"}, {"role": "assistant", "content": "Hello Reply"}]
#     messages = [{
#         "role":
#         "user",
#         "content": [{
#             "type": "image",
#             "source": {
#                 "type": "base64",
#                 "media_type": "image1_media_type",
#                 "data": "image1_data",
#             },
#         }, {
#             "type": "text",
#             "text": "Describe this image."
#         }],
#     }]
#     print(ctx(messages, 1606))

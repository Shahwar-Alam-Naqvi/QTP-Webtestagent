import re
import math
import logging
import tiktoken
import base64
from PIL import Image
from io import BytesIO
from urllib import request
from typing import List, Union, Tuple, Dict, Literal


class OpenAIContextManagement:
    """
    Manages context for OpenAI's language models, including token counting, padding, chunking, 
    and handling of image content tokens.

    Attributes:
        encoding: Token encoding mechanism based on the provided model name.
    """

    def __init__(self, **kwargs) -> None:
        """
        Initializes the OpenAIContextManagement with the given model name.

        Args:
            kwargs: Arbitrary keyword arguments that must include:
                - model_name (str): The model name to use for token encoding.

        Raises:
            AssertionError: If `model_name` is not provided in the kwargs.
        """
        assert "model_name" in kwargs, f"`model_name` key not provided in __init__. Please provide a model name."
        self.encoding = tiktoken.encoding_for_model(kwargs.get("model_name"))

    def getImageDimensions(self, image: str):  # base64 or url
        """
        Gets the dimensions of an image given its base64 string or URL.

        Args:
            image (str): Base64 string or URL of an image.

        Returns:
            Tuple[int, int]: Width and height of the image.

        Raises:
            ValueError: If the input image is not a URL or Base64 string.
        """
        url_regex = r'https?:\/\/(www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b([-a-zA-Z0-9()@:%_\+.~#?&//=]*)'
        if re.match(url_regex, image):
            response = request.urlopen(image)
            image = Image.open(response)
            return image.size
        elif re.match(r'data:image\/\w+;base64', image):
            image = re.sub(r'data:image\/\w+;base64,', '', image)
            image = Image.open(BytesIO(base64.b64decode(image)))
            return image.size
        else:
            raise ValueError("Image must be a URL or Base64 string")

    def calculateImageTokens(self,
                             image: str,
                             detail: Literal["high", "low"] = "low"):
        """
        Calculates the number of tokens required for an image based on its detail level.

        Args:
            image (str): Base64 string or URL of an image.
            detail (Literal["high", "low"], optional): The detail level for token calculation. Defaults to "low".

        Returns:
            int: Number of tokens estimated for the image.

        Raises:
            ValueError: If the provided detail level is invalid.
        """
        assert detail in [
            "high", "low"
        ], ValueError(f"Invalid detail option: {detail}. Use 'low' or 'high'")
        LOW_DETAIL_COST = 85
        HIGH_DETAIL_COST_PER_TILE = 170
        ADDITIONAL_COST = 85

        if detail == "low":
            return LOW_DETAIL_COST
        elif detail == "high":
            width, height = self.getImageDimensions(image)
            if max(width, height) >= 2048:
                ratio = 2048 / max(width, height)
                width = int(width * ratio)
                height = int(height * ratio)

            if min(width, height) > 768:
                ratio = 768 / min(width, height)
                width = int(width * ratio)
                height = int(height * ratio)

            num_squares = math.ceil(width / 512) * math.ceil(height / 512)

            total_tokens = num_squares * HIGH_DETAIL_COST_PER_TILE + ADDITIONAL_COST

            return total_tokens
        else:
            raise ValueError(
                f"Invalid detail option: {detail}. Use 'low' or 'high'")

    def __count_tokens__(self, content: str):
        """
        Counts the number of tokens in the given content.

        Args:
            content (str): The content whose tokens need to be counted.

        Returns:
            int: Number of tokens in the content.
        """
        tokens = self.encoding.encode(content)
        return len(tokens)

    def __pad_tokens__(self, content: str, max_tokens: int):
        """
        Pads the tokens of the content to the specified maximum length.

        Args:
            content (str): The content to pad.
            max_tokens (int): The maximum number of tokens to keep.

        Returns:
            str: The padded content.
        """
        tokens = self.encoding.encode(content)
        tokens_to_keep = tokens[:max_tokens]
        return self.encoding.decode(tokens_to_keep)

    def __return_chunks__(self,
                          content: str,
                          max_tokens: int,
                          overlap: int = 20):
        """
        Splits the content into chunks of tokens with optional overlap.

        Args:
            content (str): The content to split.
            max_tokens (int): The maximum number of tokens in each chunk.
            overlap (int, optional): The number of overlapping tokens between chunks. Defaults to 20.

        Returns:
            List[str]: The content split into chunks.
        """
        content_tokens = self.encoding.encode(content)
        chunks = []
        for ix in range(0, len(content_tokens), max_tokens):
            if ix > 0:
                chunks.append(
                    self.encoding.decode(content_tokens[ix - overlap:ix +
                                                        max_tokens]))
            else:
                chunks.append(
                    self.encoding.decode(content_tokens[ix:ix + max_tokens]))
        return chunks

    def __call__(self, messages: List[Dict], max_context_length: int):
        """
        Manages the context of messages, organizing them according to roles, and limits the total token count.

        Args:
            messages (List[Dict]): The list of messages to manage.
            max_context_length (int): The maximum context length in tokens.

        Returns:
            List[Dict]: The managed messages.
        """
        system_message = None
        if messages[0].get("role") == "system":
            system_message = messages[0]
        image_content_token_count = 0
        total_image_tokens = 0
        messages = messages[1:]
        messages = messages[::-1]
        previous_role = None
        current_token_num = 0
        managed_message = []
        for ix, message in enumerate(messages):
            content = message.get("content")
            role = message.get("role")
            if isinstance(content, str):
                num_tokens = self.__count_tokens__(content)
                if current_token_num + num_tokens >= max_context_length:
                    num_tokens_to_keep = max_context_length - current_token_num - 1
                    if num_tokens_to_keep <= 0:
                        break
                    content = self.__pad_tokens__(content, num_tokens_to_keep)
            elif isinstance(content, list):
                content_op = []
                for cont in content[::-1]:
                    if cont.get("type") == "image_url":
                        num_img_tokens = self.calculateImageTokens(
                            cont.get("image_url").get("url"))
                        if current_token_num + num_img_tokens + image_content_token_count >= max_context_length:
                            break
                        else:
                            content_op.append(cont)
                            image_content_token_count += num_img_tokens
                            total_image_tokens += num_img_tokens
                    elif cont.get("type") == "text":
                        num_tokens = self.__count_tokens__(cont.get("text"))
                        if current_token_num + image_content_token_count + num_tokens >= max_context_length:
                            num_tokens_to_keep = max_context_length - current_token_num
                            if num_tokens_to_keep <= 0:
                                break
                            txt = self.__pad_tokens__(cont.get("text"),
                                                      num_tokens_to_keep)
                            cont["text"] = txt
                            image_content_token_count += num_tokens_to_keep
                            total_image_tokens += num_tokens_to_keep
                        else:
                            image_content_token_count += num_tokens
                            total_image_tokens += num_tokens
                        content_op.append(cont)
                content = content_op[::-1]

            if ix > 0:
                if previous_role == role:
                    if isinstance(content, str):
                        # add message content to last message content in the managed messages list
                        managed_message[-1]["content"] += f"\n{content}"
                    elif isinstance(content, list):
                        managed_message[-1]["content"] += content
                else:
                    managed_message.append({"content": content, "role": role})
            else:
                managed_message.append({"content": content, "role": role})
            if isinstance(content, str):
                current_token_num += self.__count_tokens__(content)
            elif isinstance(content, list):
                current_token_num += image_content_token_count
                image_content_token_count = 0
            previous_role = role
        managed_message = managed_message[::-1]
        if system_message:
            system_message_tokens = self.__count_tokens__(
                system_message.get("content"))
            managed_message = [system_message] + managed_message
        else:
            system_message_tokens = 0
        logging.debug(f"SYSTEM MESSAGE TOKENS: {system_message_tokens}")
        logging.debug(f"IMAGE TOKENS: {total_image_tokens}")
        logging.debug(
            f"TOTAL TOKENS: {current_token_num + system_message_tokens}")
        print(f"SYSTEM MESSAGE TOKENS: {system_message_tokens}")
        print(f"IMAGE TOKENS: {total_image_tokens}")
        print(
            f"TOTAL TOKENS: {current_token_num + system_message_tokens}")
        return managed_message

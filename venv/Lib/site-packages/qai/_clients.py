import logging
from .llms.openai.llm import OpenAILLM
from .llms.claude.llm import ClaudeLLM
from .llms.bedrock.llama.llm import LlamaLLM
from .llms.openai.tokenizer.context import OpenAIContextManagement
from .llms.claude.tokenizer.context import ClaudeContextManagement
from .llms.bedrock.context.manager import LLamaContextManagement


class AsyncQAIOpenAI:
    """
    Manages asynchronous interactions with OpenAI's language models.
    """

    def __init__(self, **kwargs):
        """
        Initializes the OpenAILLM instance with the provided arguments.
        """
        self.llm = OpenAILLM(**kwargs)


class OpenAIContextManager:
    """
    Manages context for interactions with OpenAI's language models.
    """

    def __init__(self, **kwargs) -> None:
        """
        Initializes the OpenAIContextManagement instance with the provided arguments.
        """
        self.manager = OpenAIContextManagement(**kwargs)


class AsyncQAIClaude:
    """
    Manages asynchronous interactions with Claude's language models.
    """

    def __init__(self, **kwargs):
        """
        Initializes the ClaudeLLM instance with the provided arguments.
        """
        self.llm = ClaudeLLM(**kwargs)


class AsyncQAILlama:
    """
    Manages asynchronous interactions with Llama's language models.
    """

    def __init__(self, **kwargs):
        """
        Initializes the LlamaLLM instance with the provided arguments.

        If `llama_model_family` is not provided, it defaults to "llama3_1".
        """
        model_family = None
        if not "llama_model_family" in kwargs:
            logging.info(
                f"`llama_model_family` argument empty for Llama. Using `llama3_1` as default. For other llama model provide name in `llama_model_family`."
            )
            model_family = "llama3_1"
        else:
            model_family = kwargs["llama_model_family"]
        self.llm = LlamaLLM(model_family=model_family)


class ClaudeContextManager:
    """
    Manages context for interactions with Claude's language models.
    """

    def __init__(self, **kwargs) -> None:
        """
        Initializes the ClaudeContextManagement instance with the provided arguments.
        """
        self.manager = ClaudeContextManagement(**kwargs)


class LlamaContextManager:
    """
    Manages context for interactions with Llama's language models.
    """

    def __init__(self, **kwargs):
        """
        Initializes the LLamaContextManagement instance with the provided arguments.

        If `llama_model_family` is not provided, it defaults to "llama3_1".
        """
        model_family = None
        if not "llama_model_family" in kwargs:
            logging.info(
                f"`llama_model_family` argument empty for Llama. Using `llama3_1` as default. For other llama model provide name in `llama_model_family`."
            )
            model_family = "llama3_1"
        else:
            model_family = kwargs["llama_model_family"]
        self.manager = LLamaContextManagement(model_name=model_family)


class QAILLMs:
    """
    Aggregates various language model instances for easy access and management.
    """

    def __init__(self, **kwargs) -> None:
        """
        Initializes instances of AsyncQAILlama, AsyncQAIOpenAI, and AsyncQAIClaude with the provided arguments.

        If `llama_model_family` is included in the arguments, it is removed after initializing AsyncQAILlama.
        """
        self.llama = AsyncQAILlama(**kwargs)
        if "llama_model_family" in kwargs:
            del kwargs["llama_model_family"]
        self.openai = AsyncQAIOpenAI(**kwargs)
        self.claude = AsyncQAIClaude(**kwargs)


class QAIContextManagers:
    """
    Aggregates various context management instances for easy access and management.
    """

    def __init__(self, **kwargs) -> None:
        """
        Initializes instances of LlamaContextManager, OpenAIContextManager, and ClaudeContextManager with the provided arguments.

        If `llama_model_family` is included in the arguments, it is removed after initializing LlamaContextManager.
        """
        self.llamaManager = LlamaContextManager(**kwargs)
        if "llama_model_family" in kwargs:
            del kwargs["llama_model_family"]
        self.openaiManager = OpenAIContextManager(**kwargs)
        self.claudeManager = ClaudeContextManager(**kwargs)
